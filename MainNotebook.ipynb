{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AorM-3WYbdMs",
        "outputId": "528493b9-ec0c-4ff2-db79-cd89647f66cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "cfrom zipfile import ZipFile\n",
        "file_name = '/content/output2.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.remove('/content/output2/PV/.DS_Store')\n",
        "os.remove('/content/output2/PV/labels/.DS_Store')"
      ],
      "metadata": {
        "id": "2I3Zj4p3Pr2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7J79XKPlsND"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load images and masks\n",
        "def load_images_and_masks(image_dir, mask_dir, target_size=(512, 512)):\n",
        "    images, masks = [], []\n",
        "    for image_name in os.listdir(image_dir):\n",
        "        img_path = os.path.join(image_dir, image_name)\n",
        "        mask_path = os.path.join(mask_dir, image_name.replace('.tif', '_label.tif'))  # Assuming masks match image names\n",
        "#         print(mask_path)\n",
        "        if os.path.exists(mask_path):\n",
        "            # Load and preprocess image and mask\n",
        "#             print(mask_path)\n",
        "            image = img_to_array(load_img(img_path, target_size=target_size))/255\n",
        "            mask = img_to_array(load_img(mask_path, target_size=target_size, color_mode=\"grayscale\"))/255\n",
        "#             print(image)\n",
        "            masks.append(mask)  # Keep as single-channel grayscale\n",
        "            images.append(image)\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Load dataset\n",
        "image_dir = r'/content/output2/PV'\n",
        "mask_dir = r'/content/output2/PV/labels'\n",
        "images, masks = load_images_and_masks(image_dir, mask_dir)\n",
        "\n",
        "# Split into train and validation sets\n",
        "# First, split into training (80%) and temp (20%) → temp will be further split\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(\n",
        "    images, masks, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Now, split `x_temp` into validation (10%) and test (10%)\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_temp, y_temp, test_size=0.5, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def iou_loss(y_true, y_pred, smooth=1e-6):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "    return 1 - iou  # Since we want to minimize loss, we use (1 - IoU)\n"
      ],
      "metadata": {
        "id": "T_xxq321jk1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def weighted_bce(y_true, y_pred, weight_background=0.2, weight_foreground=0.8):\n",
        "    \"\"\"Weighted Binary Cross-Entropy Loss\"\"\"\n",
        "    bce = K.binary_crossentropy(y_true, y_pred)\n",
        "    weights = y_true * weight_foreground + (1 - y_true) * weight_background\n",
        "    return K.mean(bce * weights)\n"
      ],
      "metadata": {
        "id": "f2A0lgt8oq2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq9ZkO37l4hq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "\n",
        "def unet_model(input_size=(512, 512, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Downsampling (Encoder)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Upsampling (Decoder)\n",
        "    u6 = UpSampling2D((2, 2))(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = UpSampling2D((2, 2))(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = UpSampling2D((2, 2))(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = UpSampling2D((2, 2))(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Initialize model\n",
        "unet = unet_model()\n",
        "unet.compile(optimizer='adam', loss=weighted_bce, metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9oM7IASl8y5",
        "outputId": "24d2d5e1-b5e7-42fc-a7ab-e657c20a815e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8410 - loss: 0.1197   "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint('unet_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = unet.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=75,\n",
        "    batch_size=4,\n",
        "    callbacks=[checkpoint]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"unet_model.keras\")"
      ],
      "metadata": {
        "id": "yW1Dbs_L5PPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc-Dse17mAWf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotx` accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orGT2SiJ4lr7"
      },
      "outputs": [],
      "source": [
        "from posixpath import isabs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def calculate_iou(y_true, y_pred, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate Intersection over Union (IoU) between true and predicted masks.\n",
        "\n",
        "    Args:\n",
        "    - y_true: Ground truth mask (numpy array or tensor of shape [H, W]).\n",
        "    - y_pred: Predicted mask (numpy array or tensor of shape [H, W]).\n",
        "    - threshold: Threshold to binarize the predicted mask (default: 0.5).\n",
        "\n",
        "    Returns:\n",
        "    - IoU score (float).\n",
        "    \"\"\"\n",
        "    # Binarize the predicted mask\n",
        "    y_pred = tf.cast(y_pred > threshold, tf.float32)\n",
        "    y_true = tf.cast(y_true > 0, tf.float32)  # Ensure ground truth is binary\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
        "\n",
        "    # Avoid division by zero\n",
        "    iou = intersection / (union + tf.keras.backend.epsilon())\n",
        "    return iou.numpy()\n",
        "\n",
        "# Example usage\n",
        "# Assuming `original_mask` and `predicted_mask` are numpy arrays of shape [H, W]\n",
        "\n",
        "\n",
        "# Predict on a single image\n",
        "def predict_and_visualize(image_path, label_path, model):\n",
        "    image = img_to_array(load_img(image_path, target_size=(512, 512))) / 255.0\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    prediction = model.predict(image)[0, ..., 0]  # Remove batch and channel dimensions\n",
        "\n",
        "    y_pred = tf.cast(prediction > 0.5, tf.float32)\n",
        "    #loading true lable\n",
        "    lab= img_to_array(load_img(label_path, target_size=(512, 512), color_mode=\"grayscale\")) / 255.0\n",
        "    # lab = np.expand_dims(image, axis=0)\n",
        "    lab= tf.squeeze(lab)\n",
        "    y_true=  tf.cast(lab> 0, tf.float32)\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
        "\n",
        "    # Avoid division by zero\n",
        "    iou = intersection / (union + tf.keras.backend.epsilon())\n",
        "    print(iou.numpy())\n",
        "\n",
        "    # Display original image and prediction\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.imshow(image[0])\n",
        "    plt.axis('off')\n",
        "    #Original mask\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Original Mask\")\n",
        "    plt.imshow(lab, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Assuming `predicted_mask` is the grayscale mask\n",
        "    threshold =0.5 # Adjust threshold as necessary\n",
        "    binary_mask = (prediction>threshold ).astype(np.uint8)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Predicted Mask\")\n",
        "    plt.imshow(binary_mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example\n",
        "predict_and_visualize('/content/output2/PV/r0493.tif','/content/output2/PV/labels/r0493_label.tif', unet)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Assuming x_train, y_train, x_val, y_val, x_test, y_test are numpy arrays\n",
        "save_path = \"/content/dataset.npz\"  # Save in an accessible directory\n",
        "\n",
        "# Save dataset in compressed format\n",
        "np.savez_compressed(save_path,\n",
        "                    x_train=x_train, y_train=y_train,\n",
        "                    x_val=x_val, y_val=y_val,\n",
        "                    x_test=x_test, y_test=y_test)\n",
        "\n",
        "print(f\"Dataset saved at: {save_path}\")\n"
      ],
      "metadata": {
        "id": "0KfNMbztkrPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)  # Flatten to 1D\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)  # Count overlapping pixels\n",
        "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
        "\n",
        "    return (2. * intersection + smooth) / (union + smooth)"
      ],
      "metadata": {
        "id": "1CmASafJIAJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from posixpath import isabs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "\n",
        "#<--------------------------------------------------------------------------------------------------------------------------->\n",
        "# Predict on a single image\n",
        "def predict_and_visualize(image_path, label_path, model):\n",
        "    image = img_to_array(load_img(image_path, target_size=(512, 512))) / 255.0\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    prediction = model.predict(image)[0, ..., 0]  # Remove batch and channel dimensions\n",
        "\n",
        "    y_pred = tf.cast(prediction > 0.5, tf.float32)\n",
        "    # print(\"Predicted Label\",y_pred)\n",
        "    #loading true lable\n",
        "    lab= img_to_array(load_img(label_path, target_size=(512, 512), color_mode=\"grayscale\")) / 255.0\n",
        "   # Remove extra dimension (512, 512, 1) → (512, 512)\n",
        "    lab= tf.squeeze(lab)\n",
        "    y_true= tf.cast(lab> 0, tf.float32)\n",
        "\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
        "\n",
        "    # Avoid division by zero\n",
        "    iou = intersection / (union + tf.keras.backend.epsilon())\n",
        "    print(\"IoU Score :\",iou.numpy())\n",
        "    #<--------------------------------------------------------------------------------------------------------------------------->\n",
        "    print(\"Dice Score: \", dice_coefficient(y_true, y_pred, smooth=1e-6))\n",
        "    # Display original image and prediction\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.imshow(image[0])\n",
        "    plt.axis('off')\n",
        "    #Original mask\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Original Mask\")\n",
        "    plt.imshow(y_true, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    #<--------------------------------------------------------------------------------------------------------------------------->\n",
        "\n",
        "# Assuming `predicted_mask` is the grayscale mask\n",
        "    threshold =0.5# Adjust threshold as necessary\n",
        "    binary_mask = (prediction > threshold).astype(np.uint8)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Predicted Mask (binary_mask)\")\n",
        "    plt.imshow(binary_mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Predicted Mask(Actual)\")\n",
        "    plt.imshow(prediction, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        " #<--------------------------------------------------------------------------------------------------------------------------->\n",
        "\n",
        "predict_and_visualize(r\"/content/output2/PV/r0361.tif\",r\"/content/output2/PV/labels/r0361_label.tif\", unet)\n"
      ],
      "metadata": {
        "id": "-sEtZfHXIDrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(x_test[20])\n",
        "plt.axis('off')\n",
        "#Original mask\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Original Mask\")\n",
        "plt.imshow(y_test[20], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "#<--------------------------------------------------------------------------------------------------------------------------->\n",
        "prediction = unet.predict(x_test[20:21])[0, ..., 0]\n",
        "#<--------------------------------------------------------------------------------------------------------------------------->\n",
        "# Assuming `predicted_mask` is the grayscale mask\n",
        "threshold =0.5# Adjust threshold as necessary\n",
        "binary_mask = (prediction > threshold).astype(np.uint8)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Predicted Mask (binary_mask)\")\n",
        "plt.imshow(binary_mask, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Predicted Mask(Actual)\")\n",
        "plt.imshow(prediction, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lc06MCPJIoi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(y_true, y_pred):\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
        "    return (intersection + tf.keras.backend.epsilon()) / (union + tf.keras.backend.epsilon())\n",
        "\n",
        "# Function to calculate Dice Score\n",
        "def calculate_dice(y_true, y_pred):\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + tf.keras.backend.epsilon()) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + tf.keras.backend.epsilon())\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)  # Convert predictions to binary\n",
        "    correct = tf.equal(y_true, y_pred)  # Compare predictions with ground truth\n",
        "    return tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "\n",
        "    true_positives = tf.reduce_sum(y_true * y_pred)  # Count correctly predicted foreground pixels\n",
        "    possible_positives = tf.reduce_sum(y_true)  # Total foreground pixels in ground truth\n",
        "    return true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "\n",
        "    true_positives = tf.reduce_sum(y_true * y_pred)  # Count correctly predicted foreground pixels\n",
        "    predicted_positives = tf.reduce_sum(y_pred)  # Total predicted foreground pixels\n",
        "    return true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
        "\n",
        "\n",
        "def evaluate_dataset(model, X, y):\n",
        "    \"\"\" Evaluate Accuracy, IoU, Precision, Recall, and Dice Score for a dataset. \"\"\"\n",
        "    iou_scores, dice_scores, accuracies, precisions, recalls = [], [], [], [], []\n",
        "    count=0\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        image = np.expand_dims(X[i], axis=0)  # Add batch dimension\n",
        "        true_mask = y[i]\n",
        "        true_mask= tf.squeeze(true_mask)\n",
        "        true_mask= tf.cast(true_mask> 0, tf.float32)\n",
        "\n",
        "        # Get model prediction\n",
        "        pred_mask = model.predict(image, verbose=0)[0, ..., 0]  # Remove batch dim\n",
        "        pred_mask =  tf.cast(pred_mask> 0.5, tf.float32)  # Convert to binary mask\n",
        "\n",
        "        # Calculate metrics\n",
        "        iou_scores.append(calculate_iou(true_mask, pred_mask))\n",
        "        dice_scores.append(calculate_dice(true_mask, pred_mask))\n",
        "        accuracies.append(accuracy(true_mask, pred_mask))\n",
        "        precisions.append(precision(true_mask, pred_mask))\n",
        "        recalls.append(recall(true_mask, pred_mask))\n",
        "        count=count+1\n",
        "        print(count)\n",
        "\n",
        "\n",
        "    # Compute mean scores\n",
        "    return {\n",
        "        \"Mean Accuracy\": np.mean(accuracies),\n",
        "        \"Mean IoU\": np.mean(iou_scores),\n",
        "        \"Mean Dice Score\": np.mean(dice_scores),\n",
        "        \"Mean Precision\": np.mean(precisions),\n",
        "        \"Mean Recall\": np.mean(recalls),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "P7KBecY4kVoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_metrics = evaluate_dataset(unet, x_train, y_train)\n",
        "val_metrics = evaluate_dataset(unet, x_val, y_val)\n",
        "test_metrics = evaluate_dataset(unet, x_test, y_test)\n",
        "\n",
        "print(\"Train Metrics:\", train_metrics)\n",
        "print(\"Validation Metrics:\", val_metrics)\n",
        "print(\"Test Metrics:\", test_metrics)\n"
      ],
      "metadata": {
        "id": "UTpcy_Ijkx1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"unet_model.keras\")"
      ],
      "metadata": {
        "id": "eUCdXwwElJbH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}